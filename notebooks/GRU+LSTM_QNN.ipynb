{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04781fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from lime import lime_tabular\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a615dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudaq.set_target(\"qpp-cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45375c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ry(theta, qubit):\n",
    "    cudaq.ry(theta, qubit)\n",
    "\n",
    "def rx(theta, qubit):\n",
    "    cudaq.rx(theta, qubit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e267271",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumFunction(Function):\n",
    "    def __init__(self, qubit_count: int, hamiltonian: cudaq.SpinOperator):\n",
    "        # Define a parameterized quantum kernel\n",
    "        @cudaq.kernel\n",
    "        def kernel(qubit_count: int, thetas: np.ndarray):\n",
    "            qubits = cudaq.qvector(qubit_count)\n",
    "            ry(thetas[0], qubits[0])\n",
    "            rx(thetas[1], qubits[0])\n",
    "\n",
    "        self.kernel = kernel\n",
    "        self.qubit_count = qubit_count\n",
    "        self.hamiltonian = hamiltonian\n",
    "\n",
    "    def run(self, theta_vals: torch.Tensor) -> torch.Tensor:\n",
    "        theta_vals_np = theta_vals.cpu().numpy()\n",
    "        q_counts = [self.qubit_count] * theta_vals_np.shape[0]\n",
    "        results = cudaq.observe(self.kernel, self.hamiltonian, q_counts, theta_vals_np)\n",
    "        exp_vals = [res.expectation() for res in results]\n",
    "\n",
    "        return torch.tensor(exp_vals, dtype=torch.float32, device=device)\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, thetas: torch.Tensor, quantum_circuit, shift) -> torch.Tensor:\n",
    "        ctx.shift = shift\n",
    "        ctx.quantum_circuit = quantum_circuit\n",
    "\n",
    "        exp_vals = ctx.quantum_circuit.run(thetas).reshape(-1, 1)\n",
    "\n",
    "        # Save values for backward\n",
    "        ctx.save_for_backward(thetas, exp_vals)\n",
    "        return exp_vals\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        thetas, _ = ctx.saved_tensors\n",
    "        gradients = torch.zeros_like(thetas, device=device)\n",
    "\n",
    "        # Parameter-shift rule\n",
    "        for i in range(thetas.shape[1]):\n",
    "            thetas_plus = thetas.clone()\n",
    "            thetas_minus = thetas.clone()\n",
    "\n",
    "            thetas_plus[:, i] += ctx.shift\n",
    "            thetas_minus[:, i] -= ctx.shift\n",
    "\n",
    "            exp_vals_plus = ctx.quantum_circuit.run(thetas_plus)\n",
    "            exp_vals_minus = ctx.quantum_circuit.run(thetas_minus)\n",
    "\n",
    "            gradients[:, i] = (exp_vals_plus - exp_vals_minus) / (2.0 * ctx.shift)\n",
    "\n",
    "        # Multiply by incoming gradient from chain rule\n",
    "        return gradients * grad_output, None, None\n",
    "\n",
    "class QuantumLayer(nn.Module):\n",
    "    def __init__(self, qubit_count: int, hamiltonian, shift: torch.Tensor):\n",
    "        super().__init__()\n",
    "        self.quantum_circuit = QuantumFunction(qubit_count, hamiltonian)\n",
    "        self.shift = shift\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        return QuantumFunction.apply(input, self.quantum_circuit, self.shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7854c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hybrid_QNN(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(Hybrid_QNN, self).__init__()\n",
    "\n",
    "        self.lstm_hidden_dim = 64\n",
    "        self.gru_hidden_dim = 32\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(input_size=num_features,\n",
    "                            hidden_size=self.lstm_hidden_dim,\n",
    "                            num_layers=1, batch_first=True)\n",
    "\n",
    "        # GRU\n",
    "        self.gru = nn.GRU(input_size=self.lstm_hidden_dim,\n",
    "                          hidden_size=self.gru_hidden_dim,\n",
    "                          num_layers=1, batch_first=True)\n",
    "\n",
    "        # Fully connected\n",
    "        self.fc1 = nn.Linear(self.gru_hidden_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 2)  # intermediate 2D before quantum\n",
    "\n",
    "        # Two separate quantum layers for two outputs\n",
    "        self.quantum1 = QuantumLayer(\n",
    "            qubit_count=2,\n",
    "            hamiltonian=cudaq.spin.z(0),\n",
    "            shift=torch.tensor(np.pi / 2)\n",
    "        )\n",
    "        self.quantum2 = QuantumLayer(\n",
    "            qubit_count=2,\n",
    "            hamiltonian=cudaq.spin.z(1),\n",
    "            shift=torch.tensor(np.pi / 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # [batch, 1, num_features]\n",
    "\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        gru_out, _ = self.gru(lstm_out)\n",
    "        x = gru_out[:, -1, :]\n",
    "\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)  # [batch, 2]\n",
    "\n",
    "        # Split into two parts for two quantum circuits\n",
    "        x1_in = x[:, 0].unsqueeze(1)  # [batch, 1]\n",
    "        x2_in = x[:, 1].unsqueeze(1)  # [batch, 1]\n",
    "\n",
    "        x1_out = self.quantum1(x1_in)  # [batch, 1]\n",
    "        x2_out = self.quantum2(x2_in)  # [batch, 1]\n",
    "\n",
    "        # Concatenate outputs back\n",
    "        x_out = torch.cat([x1_out, x2_out], dim=1)  # [batch, 2]\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3d202d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: torch.Size([5185, 13]) torch.Size([5185, 2])\n",
      "Test shape:  torch.Size([577, 13]) torch.Size([577, 2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "dataset_path = \"../data/noalpha.csv\"  # Adjust to your CSV path\n",
    "data = load_data(dataset_path)\n",
    "\n",
    "# Identify only the numeric columns\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Fill missing values in numeric columns with their column-wise mean\n",
    "data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].mean())\n",
    "\n",
    "features = ['RAdeg', 'DEdeg', 'e_RAdeg', 'e_DEdeg', 'RApeak',\n",
    "            'DEpeak', 'Sint', 'e_Sint', 'Speak', 'e_Speak', 'rmspeak', 'e_rmspeak', 'PA']\n",
    "\n",
    "target = ['thetamaj', 'thetamin']\n",
    "X = data[features].values\n",
    "y = data[target].values\n",
    "\n",
    "# Normalize\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X = scaler_X.fit_transform(X)\n",
    "y = scaler_y.fit_transform(y)\n",
    "\n",
    "# Convert to torch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test shape: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eb6b48c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.993080, Std Dev: 0.000000\n",
      "Epoch 2/50, Loss: 1.992085, Std Dev: 0.000498\n",
      "Epoch 3/50, Loss: 1.990792, Std Dev: 0.000937\n",
      "Epoch 4/50, Loss: 1.989176, Std Dev: 0.001462\n",
      "Epoch 5/50, Loss: 1.987215, Std Dev: 0.002088\n",
      "Epoch 6/50, Loss: 1.984910, Std Dev: 0.002815\n",
      "Epoch 7/50, Loss: 1.982338, Std Dev: 0.003626\n",
      "Epoch 8/50, Loss: 1.979312, Std Dev: 0.004557\n",
      "Epoch 9/50, Loss: 1.975771, Std Dev: 0.005633\n",
      "Epoch 10/50, Loss: 1.971398, Std Dev: 0.006924\n",
      "Epoch 11/50, Loss: 1.966471, Std Dev: 0.008413\n",
      "Epoch 12/50, Loss: 1.960780, Std Dev: 0.010122\n",
      "Epoch 13/50, Loss: 1.954242, Std Dev: 0.012076\n",
      "Epoch 14/50, Loss: 1.946420, Std Dev: 0.014353\n",
      "Epoch 15/50, Loss: 1.937231, Std Dev: 0.017008\n",
      "Epoch 16/50, Loss: 1.926677, Std Dev: 0.020072\n",
      "Epoch 17/50, Loss: 1.913996, Std Dev: 0.023660\n",
      "Epoch 18/50, Loss: 1.899322, Std Dev: 0.027829\n",
      "Epoch 19/50, Loss: 1.882379, Std Dev: 0.032642\n",
      "Epoch 20/50, Loss: 1.861427, Std Dev: 0.038349\n",
      "Epoch 21/50, Loss: 1.836769, Std Dev: 0.045076\n",
      "Epoch 22/50, Loss: 1.809986, Std Dev: 0.052722\n",
      "Epoch 23/50, Loss: 1.778223, Std Dev: 0.061525\n",
      "Epoch 24/50, Loss: 1.742857, Std Dev: 0.071497\n",
      "Epoch 25/50, Loss: 1.699189, Std Dev: 0.083133\n",
      "Epoch 26/50, Loss: 1.654849, Std Dev: 0.095998\n",
      "Epoch 27/50, Loss: 1.604941, Std Dev: 0.110260\n",
      "Epoch 28/50, Loss: 1.549831, Std Dev: 0.126002\n",
      "Epoch 29/50, Loss: 1.497141, Std Dev: 0.142583\n",
      "Epoch 30/50, Loss: 1.448853, Std Dev: 0.159385\n",
      "Epoch 31/50, Loss: 1.404320, Std Dev: 0.176035\n",
      "Epoch 32/50, Loss: 1.380472, Std Dev: 0.191015\n",
      "Epoch 33/50, Loss: 1.372659, Std Dev: 0.203663\n",
      "Epoch 34/50, Loss: 1.377450, Std Dev: 0.213797\n",
      "Epoch 35/50, Loss: 1.389271, Std Dev: 0.221632\n",
      "Epoch 36/50, Loss: 1.397543, Std Dev: 0.227839\n",
      "Epoch 37/50, Loss: 1.398477, Std Dev: 0.233051\n",
      "Epoch 38/50, Loss: 1.386414, Std Dev: 0.237962\n",
      "Epoch 39/50, Loss: 1.370577, Std Dev: 0.242764\n",
      "Epoch 40/50, Loss: 1.350225, Std Dev: 0.247647\n",
      "Epoch 41/50, Loss: 1.331302, Std Dev: 0.252550\n",
      "Epoch 42/50, Loss: 1.315878, Std Dev: 0.257340\n",
      "Epoch 43/50, Loss: 1.307457, Std Dev: 0.261779\n",
      "Epoch 44/50, Loss: 1.308373, Std Dev: 0.265595\n",
      "Epoch 45/50, Loss: 1.308314, Std Dev: 0.268905\n",
      "Epoch 46/50, Loss: 1.309157, Std Dev: 0.271747\n",
      "Epoch 47/50, Loss: 1.305249, Std Dev: 0.274316\n",
      "Epoch 48/50, Loss: 1.297413, Std Dev: 0.276752\n",
      "Epoch 49/50, Loss: 1.291260, Std Dev: 0.279025\n",
      "Epoch 50/50, Loss: 1.284596, Std Dev: 0.281165\n"
     ]
    }
   ],
   "source": [
    "model = Hybrid_QNN(num_features=len(features)).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "epochs = 50\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_hat_train = model(X_train)\n",
    "    loss = loss_function(y_hat_train, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    std_loss = np.std(losses)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.6f}, Std Dev: {std_loss:.6f}\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5d344257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== MODEL EVALUATION =====\n",
      "Test Loss (MSELoss): 1.307831\n",
      "Test MSE:  1.3078, Accuracy by error: 88.79%\n",
      "Test RMSE: 1.1436, Accuracy by error: 90.20%\n",
      "Test MAE:  0.7646, Accuracy by error: 93.45%\n",
      "Test R^2:  -0.2323\n",
      "Model Size: 0.17 MB\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# ===== EVALUATION =====\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_hat_test = model(X_test)\n",
    "\n",
    "# ---- Shape checks ----\n",
    "if y_hat_test is None:\n",
    "    raise ValueError(\"Model returned None. Check QuantumLayer.forward().\")\n",
    "\n",
    "if y_hat_test.shape != y_test.shape:\n",
    "    raise ValueError(\n",
    "        f\"Shape mismatch: y_hat_test {y_hat_test.shape} vs y_test {y_test.shape}\"\n",
    "    )\n",
    "\n",
    "# ---- Loss ----\n",
    "test_loss = loss_function(y_hat_test, y_test).item()\n",
    "\n",
    "# Convert to numpy for sklearn metrics\n",
    "y_true_np = y_test.cpu().numpy()\n",
    "y_pred_np = y_hat_test.cpu().numpy()\n",
    "\n",
    "# Metrics\n",
    "r2_score_value = r2_score(y_true_np, y_pred_np, multioutput='uniform_average')\n",
    "mae_score_value = mean_absolute_error(y_true_np, y_pred_np)\n",
    "rmse_score_value = np.sqrt(mean_squared_error(y_true_np, y_pred_np))\n",
    "mse_score_value = mean_squared_error(y_true_np, y_pred_np)\n",
    "\n",
    "# Accuracy-like metrics\n",
    "y_max = np.max(y_true_np, axis=0)\n",
    "y_min = np.min(y_true_np, axis=0)\n",
    "alpha = y_max - y_min\n",
    "\n",
    "mae_accuracy = (1 - mae_score_value / alpha.mean()) * 100\n",
    "rmse_accuracy = (1 - rmse_score_value / alpha.mean()) * 100\n",
    "mse_accuracy  = (1 - mse_score_value / alpha.mean()) * 100\n",
    "\n",
    "# Model size in MB\n",
    "model_size_mb = sum(p.numel() * p.element_size() for p in model.parameters()) / (1024**2)\n",
    "\n",
    "# ---- Print results ----\n",
    "print(\"\\n===== MODEL EVALUATION =====\")\n",
    "print(f\"Test Loss (MSELoss): {test_loss:.6f}\")\n",
    "print(f\"Test MSE:  {mse_score_value:.4f}, Accuracy by error: {mse_accuracy:.2f}%\")\n",
    "print(f\"Test RMSE: {rmse_score_value:.4f}, Accuracy by error: {rmse_accuracy:.2f}%\")\n",
    "print(f\"Test MAE:  {mae_score_value:.4f}, Accuracy by error: {mae_accuracy:.2f}%\")\n",
    "print(f\"Test R^2:  {r2_score_value:.4f}\")\n",
    "print(f\"Model Size: {model_size_mb:.2f} MB\")\n",
    "print(\"=============================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf36930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c45986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

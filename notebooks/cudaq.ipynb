{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35bde0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb134e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudaq.set_target(\"nvidia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c7ce9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ry(theta, qubit):\n",
    "    cudaq.ry(theta, qubit)\n",
    "\n",
    "def rx(theta, qubit):\n",
    "    cudaq.rx(theta, qubit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ce46e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define quantum function using CUDA-Q\n",
    "class QuantumFunction(Function):\n",
    "    def __init__(self, qubit_count: int, hamiltonian: cudaq.SpinOperator):\n",
    "        @cudaq.kernel\n",
    "        def kernel(qubit_count: int, thetas: np.ndarray):\n",
    "            qubits = cudaq.qvector(qubit_count)\n",
    "            ry(thetas[0], qubits[0])\n",
    "            rx(thetas[1], qubits[0])\n",
    "        self.kernel = kernel\n",
    "        self.qubit_count = qubit_count\n",
    "        self.hamiltonian = hamiltonian\n",
    "\n",
    "    def run(self, theta_vals: torch.Tensor) -> torch.Tensor:\n",
    "        theta_vals_np = theta_vals.cpu().numpy()\n",
    "        qubit_count = [self.qubit_count] * theta_vals_np.shape[0]\n",
    "        results = cudaq.observe(self.kernel, self.hamiltonian, qubit_count, theta_vals_np)\n",
    "        return torch.tensor([res.expectation() for res in results], dtype=torch.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, thetas: torch.Tensor, quantum_circuit, shift) -> torch.Tensor:\n",
    "        ctx.shift = shift\n",
    "        ctx.quantum_circuit = quantum_circuit\n",
    "        exp_vals = ctx.quantum_circuit.run(thetas).reshape(-1, 1)\n",
    "        ctx.save_for_backward(thetas, exp_vals)\n",
    "        return exp_vals\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        thetas, _ = ctx.saved_tensors\n",
    "        gradients = torch.zeros_like(thetas)\n",
    "        for i in range(thetas.shape[1]):\n",
    "            thetas_plus = thetas.clone()\n",
    "            thetas_plus[:, i] += ctx.shift\n",
    "            thetas_minus = thetas.clone()\n",
    "            thetas_minus[:, i] -= ctx.shift\n",
    "            exp_plus = ctx.quantum_circuit.run(thetas_plus)\n",
    "            exp_minus = ctx.quantum_circuit.run(thetas_minus)\n",
    "            gradients[:, i] = (exp_plus - exp_minus) / (2 * ctx.shift)\n",
    "        return gradients * grad_output, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2aed3739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantum layer\n",
    "class QuantumLayer(nn.Module):\n",
    "    def __init__(self, qubit_count: int, hamiltonian, shift: torch.Tensor):\n",
    "        super().__init__()\n",
    "        self.quantum_circuit = QuantumFunction(qubit_count, hamiltonian)\n",
    "        self.shift = shift\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        return QuantumFunction.apply(input, self.quantum_circuit, self.shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d11e2ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid QNN model\n",
    "class Hybrid_QNN(nn.Module):\n",
    "    def __init__(self, input_dim=8):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.fc5 = nn.Linear(32, 2)\n",
    "        self.quantum = QuantumLayer(qubit_count=2, hamiltonian=cudaq.spin.z(0), shift=torch.tensor(np.pi / 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = self.quantum(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70c96697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'ID', 'RAdeg', 'DEdeg', 'e_RAdeg', 'e_DEdeg', 'RApeak',\n",
       "       'DEpeak', 'Sint', 'e_Sint', 'Speak', 'e_Speak', 'rmspeak', 'e_rmspeak',\n",
       "       'thetamaj', 'thetamin', 'PA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/noalpha.csv\")\n",
    "df.head()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e74b688",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(columns=['thetamaj', 'thetamin','ID','Unnamed: 0'])\n",
    "target_ma = df['thetamaj'].values.reshape(-1, 1)\n",
    "target_mi = df['thetamin'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0af26a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features and targets\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y_ma = MinMaxScaler()\n",
    "scaler_y_mi = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(features)\n",
    "y_ma_scaled = scaler_y_ma.fit_transform(target_ma).flatten()\n",
    "y_mi_scaled = scaler_y_mi.fit_transform(target_mi).flatten()\n",
    "\n",
    "X_train, X_test, y_train_ma, y_test_ma = train_test_split(X_scaled, y_ma_scaled, test_size=0.2, random_state=42)\n",
    "_, _, y_train_mi, y_test_mi = train_test_split(X_scaled, y_mi_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_ma_tensor = torch.tensor(y_train_ma, dtype=torch.float32)\n",
    "y_test_ma_tensor = torch.tensor(y_test_ma, dtype=torch.float32)\n",
    "y_train_mi_tensor = torch.tensor(y_train_mi, dtype=torch.float32)\n",
    "y_test_mi_tensor = torch.tensor(y_test_mi, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33734cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train function\n",
    "def train_model(model, X_train, y_train, epochs=50, lr=0.001):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train).flatten()\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c21cf390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.807598\n",
      "Epoch 2/50, Loss: 0.798762\n",
      "Epoch 3/50, Loss: 0.787685\n",
      "Epoch 4/50, Loss: 0.773179\n",
      "Epoch 5/50, Loss: 0.754731\n",
      "Epoch 6/50, Loss: 0.731046\n",
      "Epoch 7/50, Loss: 0.700728\n",
      "Epoch 8/50, Loss: 0.661586\n",
      "Epoch 9/50, Loss: 0.611638\n",
      "Epoch 10/50, Loss: 0.547862\n",
      "Epoch 11/50, Loss: 0.469849\n",
      "Epoch 12/50, Loss: 0.378831\n",
      "Epoch 13/50, Loss: 0.277388\n",
      "Epoch 14/50, Loss: 0.177474\n",
      "Epoch 15/50, Loss: 0.092216\n",
      "Epoch 16/50, Loss: 0.034869\n",
      "Epoch 17/50, Loss: 0.011978\n",
      "Epoch 18/50, Loss: 0.009944\n",
      "Epoch 19/50, Loss: 0.010963\n",
      "Epoch 20/50, Loss: 0.013482\n",
      "Epoch 21/50, Loss: 0.030384\n",
      "Epoch 22/50, Loss: 0.058046\n",
      "Epoch 23/50, Loss: 0.073446\n",
      "Epoch 24/50, Loss: 0.066947\n",
      "Epoch 25/50, Loss: 0.047648\n",
      "Epoch 26/50, Loss: 0.029094\n",
      "Epoch 27/50, Loss: 0.020258\n",
      "Epoch 28/50, Loss: 0.018623\n",
      "Epoch 29/50, Loss: 0.020944\n",
      "Epoch 30/50, Loss: 0.023913\n",
      "Epoch 31/50, Loss: 0.025931\n",
      "Epoch 32/50, Loss: 0.026461\n",
      "Epoch 33/50, Loss: 0.025176\n",
      "Epoch 34/50, Loss: 0.023582\n",
      "Epoch 35/50, Loss: 0.021441\n",
      "Epoch 36/50, Loss: 0.018638\n",
      "Epoch 37/50, Loss: 0.016201\n",
      "Epoch 38/50, Loss: 0.014168\n",
      "Epoch 39/50, Loss: 0.012179\n",
      "Epoch 40/50, Loss: 0.010645\n",
      "Epoch 41/50, Loss: 0.009507\n",
      "Epoch 42/50, Loss: 0.008726\n",
      "Epoch 43/50, Loss: 0.008258\n",
      "Epoch 44/50, Loss: 0.008123\n",
      "Epoch 45/50, Loss: 0.008403\n",
      "Epoch 46/50, Loss: 0.008376\n",
      "Epoch 47/50, Loss: 0.008845\n",
      "Epoch 48/50, Loss: 0.008733\n",
      "Epoch 49/50, Loss: 0.008772\n",
      "Epoch 50/50, Loss: 0.008846\n"
     ]
    }
   ],
   "source": [
    "model_ma = Hybrid_QNN(input_dim=X_train.shape[1])\n",
    "train_model(model_ma, X_train_tensor, y_train_ma_tensor)\n",
    "model_ma.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_ma = model_ma(X_test_tensor).cpu().numpy().flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1ad1109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Thetamaj Metrics ---\n",
      "R2: -0.7333278656005859\n",
      "MAE: 0.06106337159872055\n",
      "RMSE: 0.08946573510055113\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Thetamaj Metrics ---\")\n",
    "print(\"R2:\", r2_score(y_test_ma_tensor, y_pred_ma))\n",
    "print(\"MAE:\", mean_absolute_error(y_test_ma_tensor, y_pred_ma))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test_ma_tensor, y_pred_ma)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7eae610d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.672833\n",
      "Epoch 2/50, Loss: 0.671109\n",
      "Epoch 3/50, Loss: 0.668764\n",
      "Epoch 4/50, Loss: 0.665352\n",
      "Epoch 5/50, Loss: 0.660326\n",
      "Epoch 6/50, Loss: 0.653236\n",
      "Epoch 7/50, Loss: 0.643732\n",
      "Epoch 8/50, Loss: 0.630749\n",
      "Epoch 9/50, Loss: 0.613111\n",
      "Epoch 10/50, Loss: 0.590126\n",
      "Epoch 11/50, Loss: 0.559494\n",
      "Epoch 12/50, Loss: 0.519679\n",
      "Epoch 13/50, Loss: 0.468061\n",
      "Epoch 14/50, Loss: 0.403064\n",
      "Epoch 15/50, Loss: 0.325401\n",
      "Epoch 16/50, Loss: 0.236109\n",
      "Epoch 17/50, Loss: 0.147110\n",
      "Epoch 18/50, Loss: 0.073611\n",
      "Epoch 19/50, Loss: 0.047446\n",
      "Epoch 20/50, Loss: 0.088637\n",
      "Epoch 21/50, Loss: 0.155979\n",
      "Epoch 22/50, Loss: 0.174367\n",
      "Epoch 23/50, Loss: 0.150303\n",
      "Epoch 24/50, Loss: 0.105869\n",
      "Epoch 25/50, Loss: 0.067706\n",
      "Epoch 26/50, Loss: 0.046013\n",
      "Epoch 27/50, Loss: 0.043807\n",
      "Epoch 28/50, Loss: 0.053214\n",
      "Epoch 29/50, Loss: 0.065629\n",
      "Epoch 30/50, Loss: 0.076858\n",
      "Epoch 31/50, Loss: 0.082522\n",
      "Epoch 32/50, Loss: 0.080754\n",
      "Epoch 33/50, Loss: 0.074716\n",
      "Epoch 34/50, Loss: 0.063468\n",
      "Epoch 35/50, Loss: 0.051418\n",
      "Epoch 36/50, Loss: 0.041387\n",
      "Epoch 37/50, Loss: 0.034594\n",
      "Epoch 38/50, Loss: 0.035303\n",
      "Epoch 39/50, Loss: 0.039455\n",
      "Epoch 40/50, Loss: 0.045885\n",
      "Epoch 41/50, Loss: 0.048130\n",
      "Epoch 42/50, Loss: 0.045869\n",
      "Epoch 43/50, Loss: 0.042228\n",
      "Epoch 44/50, Loss: 0.036310\n",
      "Epoch 45/50, Loss: 0.031354\n",
      "Epoch 46/50, Loss: 0.029667\n",
      "Epoch 47/50, Loss: 0.029603\n",
      "Epoch 48/50, Loss: 0.031912\n",
      "Epoch 49/50, Loss: 0.032197\n",
      "Epoch 50/50, Loss: 0.032723\n",
      "\n",
      "--- Thetamin Metrics ---\n",
      "R2: -2.07453989982605\n",
      "MAE: 0.1364080011844635\n",
      "RMSE: 0.1644613039696626\n"
     ]
    }
   ],
   "source": [
    "model_mi = Hybrid_QNN(input_dim=X_train.shape[1])\n",
    "train_model(model_mi, X_train_tensor, y_train_mi_tensor)\n",
    "model_mi.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_mi = model_mi(X_test_tensor).cpu().numpy().flatten()\n",
    "\n",
    "print(\"\\n--- Thetamin Metrics ---\")\n",
    "print(\"R2:\", r2_score(y_test_mi_tensor, y_pred_mi))\n",
    "print(\"MAE:\", mean_absolute_error(y_test_mi_tensor, y_pred_mi))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test_mi_tensor, y_pred_mi)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
